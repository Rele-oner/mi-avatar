<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI 3D Motion Capture - Gemini Dev</title>
    
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/holistic/holistic.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>

    <style>
        body { margin: 0; background: #0a0a0a; color: #00ffcc; font-family: 'Segoe UI', sans-serif; overflow: hidden; }
        .ui-container { position: absolute; top: 0; left: 0; width: 100%; display: flex; justify-content: space-between; padding: 20px; box-sizing: border-box; pointer-events: none; z-index: 10; }
        .view-panel { background: rgba(0,0,0,0.7); border: 1px solid #00ffcc; border-radius: 8px; padding: 10px; pointer-events: auto; }
        #canvas_container { width: 100vw; height: 100vh; cursor: move; }
        video { display: none; }
        #capture_preview { width: 200px; height: 150px; border: 1px solid #555; transform: rotateY(180deg); }
        .loader { position: fixed; top: 0; left: 0; width: 100%; height: 100%; background: #000; display: flex; justify-content: center; align-items: center; z-index: 100; font-weight: bold; }
    </style>
</head>
<body>

    <div id="loader" class="loader">INICIALIZANDO MOTOR 3D Y RED NEURONAL...</div>

    <div class="ui-container">
        <div class="view-panel">
            <small>VISTA DE CAPTURA</small><br>
            <video id="webcam"></video>
            <canvas id="capture_preview"></canvas>
        </div>
        <div class="view-panel" style="text-align: right;">
            <strong>ESTADO: </strong> <span id="status">Buscando...</span><br>
            <small>Usa el ratón para rotar la cámara 3D</small>
        </div>
    </div>

    <div id="canvas_container"></div>

    <script type="module">
        // --- CONFIGURACIÓN THREE.JS (EL MUNDO 3D) ---
        const container = document.getElementById('canvas_container');
        const scene = new THREE.Scene();
        scene.background = new THREE.Color(0x050505);
        
        const camera3D = new THREE.PerspectiveCamera(45, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera3D.position.set(0, 0, 3);

        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        container.appendChild(renderer.domElement);

        // Luces
        const light = new THREE.PointLight(0x00ffcc, 1, 100);
        light.position.set(0, 10, 10);
        scene.add(light);
        scene.add(new THREE.AmbientLight(0x404040));

        // --- CREACIÓN DEL AVATAR (MONIGOTE 3D) ---
        const bones = {};
        const boneMaterial = new THREE.MeshStandardMaterial({ color: 0x00ffcc, emissive: 0x004433 });
        const jointMaterial = new THREE.MeshStandardMaterial({ color: 0xffffff });

        function createJoint(name, x, y, z) {
            const geo = new THREE.SphereGeometry(0.04, 16, 16);
            const mesh = new THREE.Mesh(geo, jointMaterial);
            mesh.position.set(x, y, z);
            scene.add(mesh);
            bones[name] = mesh;
            return mesh;
        }

        // Definimos articulaciones principales (Medio cuerpo)
        const jointNames = [
            'nose', 'leftShoulder', 'rightShoulder', 'leftElbow', 
            'rightElbow', 'leftWrist', 'rightWrist', 'mouthLeft', 'mouthRight'
        ];
        jointNames.forEach(name => createJoint(name, 0, 0, 0));

        // --- PROCESAMIENTO DE IA ---
        const videoElement = document.getElementById('webcam');
        const canvasPreview = document.getElementById('capture_preview');
        const ctxPre = canvasPreview.getContext('2d');
        const statusText = document.getElementById('status');

        function onResults(results) {
            document.getElementById('loader').style.display = "none";
            
            // Dibujar preview pequeña
            canvasPreview.width = 200;
            canvasPreview.height = 150;
            ctxPre.save();
            ctxPre.clearRect(0, 0, 200, 150);
            ctxPre.drawImage(results.image, 0, 0, 200, 150);
            ctxPre.restore();

            if (results.poseLandmarks) {
                statusText.innerText = "TRACKING ACTIVO";
                statusText.style.color = "#00ffcc";

                // Función para mapear coordenadas de MediaPipe (0 a 1) a Three.js (-1 a 1)
                const mapCoords = (landmark) => ({
                    x: (landmark.x - 0.5) * -2, // Invertido para efecto espejo
                    y: (landmark.y - 0.5) * -2,
                    z: -landmark.z * 2 // Profundidad
                });

                // Actualizar posiciones de los huesos 3D
                const pose = results.poseLandmarks;
                
                const parts = {
                    'nose': pose[0],
                    'leftShoulder': pose[11],
                    'rightShoulder': pose[12],
                    'leftElbow': pose[13],
                    'rightElbow': pose[14],
                    'leftWrist': pose[15],
                    'rightWrist': pose[16]
                };

                for (let key in parts) {
                    if (bones[key]) {
                        const pos = mapCoords(parts[key]);
                        bones[key].position.lerp(new THREE.Vector3(pos.x, pos.y, pos.z), 0.5);
                    }
                }
            } else {
                statusText.innerText = "BUSCANDO SUJETO...";
                statusText.style.color = "red";
            }

            renderer.render(scene, camera3D);
        }

        const holistic = new Holistic({locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/holistic/${file}`;
        }});

        holistic.setOptions({
            modelComplexity: 1,
            smoothLandmarks: true,
            minDetectionConfidence: 0.7
        });

        holistic.onResults(onResults);

        const camera = new Camera(videoElement, {
            onFrame: async () => { await holistic.send({image: videoElement}); },
            width: 640, height: 480
        });
        camera.start();

        // Ajustar ventana
        window.addEventListener('resize', () => {
            camera3D.aspect = window.innerWidth / window.innerHeight;
            camera3D.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });

    </script>
</body>
</html>
