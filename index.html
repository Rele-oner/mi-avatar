<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>AI Avatar - V24 Safe-Core</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
    <style>
        body { margin: 0; background: #050505; overflow: hidden; font-family: 'Courier New', monospace; color: #00ffcc; }
        #debug-panel { position: absolute; top: 10px; left: 10px; z-index: 100; font-size: 11px; background: rgba(0,0,0,0.8); padding: 10px; border: 1px solid #00ffcc33; }
        canvas { width: 100vw; height: 100vh; transform: rotateY(180deg); object-fit: contain; }
        video { display: none; }
        .loading { position: fixed; inset: 0; display: flex; align-items: center; justify-content: center; background: #000; z-index: 50; flex-direction: column; }
        .dot { animation: blink 1s infinite; }
        @keyframes blink { 0%, 100% { opacity: 0; } 50% { opacity: 1; } }
    </style>
</head>
<body>
    <div id="debug-panel">
        <div>LOG: <span id="log">INICIANDO...</span></div>
        <div>FPS: <span id="fps">0</span></div>
        <div>IA_STATUS: <span id="ia">ESPERANDO</span></div>
    </div>

    <div id="loader" class="loading">
        <h2 style="letter-spacing: 5px;">SISTEMA V24<span class="dot">_</span></h2>
        <p id="sub-msg" style="font-size: 10px; opacity: 0.5;">CARGANDO COMPONENTES NEURALES...</p>
    </div>

    <canvas id="out"></canvas>
    <video id="v" playsinline></video>

<script type="module">
    const video = document.getElementById('v');
    const canvas = document.getElementById('out');
    const ctx = canvas.getContext('2d');
    const log = document.getElementById('log');
    let lastTime = 0;

    function updateLog(txt) { log.innerText = txt; }

    function onResults(res) {
        document.getElementById('loader').style.display = 'none';
        document.getElementById('ia').innerText = "OK";
        
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        
        // Dibujamos el video original con un filtro para saber que funciona
        ctx.save();
        ctx.filter = "brightness(0.6) sepia(1) hue-rotate(140deg) saturate(3)";
        ctx.drawImage(res.image, 0, 0, canvas.width, canvas.height);
        ctx.restore();

        // Dibujamos la máscara IA encima
        if (res.multiFaceLandmarks && res.multiFaceLandmarks.length > 0) {
            const face = res.multiFaceLandmarks[0];
            ctx.fillStyle = "#fff";
            [468, 473].forEach(idx => {
                const p = face[idx];
                ctx.beginPath();
                ctx.arc(p.x * canvas.width, p.y * canvas.height, 6, 0, 7);
                ctx.fill();
            });
        }

        const now = performance.now();
        document.getElementById('fps').innerText = Math.round(1000 / (now - lastTime));
        lastTime = now;
    }

    // Inicialización paso a paso
    updateLog("CONFIGURANDO FACE_MESH...");
    const faceMesh = new FaceMesh({
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
    });

    faceMesh.setOptions({
        maxNumFaces: 1,
        refineLandmarks: true,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5
    });

    faceMesh.onResults(onResults);

    updateLog("SOLICITANDO CÁMARA...");
    const camera = new Camera(video, {
        onFrame: async () => {
            updateLog("PROCESANDO FRAME...");
            await faceMesh.send({image: video});
        },
        width: 640, height: 480
    });

    camera.start()
        .then(() => updateLog("CÁMARA OK - ESPERANDO IA"))
        .catch(e => {
            updateLog("ERROR CÁMARA");
            document.getElementById('sub-msg').innerText = "ERROR DE ACCESO A HARDWARE";
        });

</script>
</body>
</html>
