<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>AI Avatar - V40 PHOENIX</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script>
    <style>
        body { margin: 0; background: #000; overflow: hidden; color: #00ffcc; font-family: 'Courier New', monospace; }
        canvas { width: 100vw; height: 100vh; transform: rotateY(180deg); position: absolute; z-index: 2; }
        video { position: fixed; bottom: 10px; right: 10px; width: 160px; border: 1px solid #00ffcc; transform: rotateY(180deg); z-index: 1; }
        #status { position: fixed; top: 20px; left: 20px; z-index: 3; font-size: 12px; }
        .dot { inline-block; width: 10px; height: 10px; background: #f00; border-radius: 50%; display: inline-block; margin-right: 10px; }
    </style>
</head>
<body>
    <div id="status"><span id="indicator" class="dot"></span> SYSTEM_V40 // CORE_RECOVERY_MODE</div>
    <video id="v" autoplay playsinline></video>
    <canvas id="out"></canvas>

<script>
    const video = document.getElementById('v');
    const canvas = document.getElementById('out');
    const ctx = canvas.getContext('2d');
    const indicator = document.getElementById('indicator');

    // 1. INICIO DE CÁMARA PURA
    async function setupCamera() {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480, frameRate: 30 } });
        video.srcObject = stream;
        return new Promise(resolve => video.onloadedmetadata = () => resolve());
    }

    async function start() {
        await setupCamera();
        video.play();

        const faceMesh = new FaceMesh({
            locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
        });

        faceMesh.setOptions({ maxNumFaces: 1, refineLandmarks: false, minDetectionConfidence: 0.5 });

        faceMesh.onResults(res => {
            indicator.style.background = "#0f0"; // IA VIVA
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            if (res.multiFaceLandmarks && res.multiFaceLandmarks[0]) {
                const face = res.multiFaceLandmarks[0];
                ctx.strokeStyle = "#00ffcc";
                ctx.lineWidth = 2;
                
                // Dibujo de supervivencia: Ojos y Óvalo Facial
                const points = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109];
                
                ctx.beginPath();
                points.forEach((idx, i) => {
                    const p = face[idx];
                    if(i === 0) ctx.moveTo(p.x * canvas.width, p.y * canvas.height);
                    else ctx.lineTo(p.x * canvas.width, p.y * canvas.height);
                });
                ctx.closePath();
                ctx.stroke();

                // Ojos brillantes
                ctx.fillStyle = "#fff";
                [468, 473].forEach(idx => {
                    const p = face[idx];
                    ctx.beginPath();
                    ctx.arc(p.x * canvas.width, p.y * canvas.height, 5, 0, 7);
                    ctx.fill();
                });
            }
            setTimeout(() => indicator.style.background = "#f00", 100);
        });

        // 2. BUCLE DE PROCESAMIENTO CONTROLADO (Evita el congelamiento)
        setInterval(async () => {
            if (video.readyState >= 2) {
                await faceMesh.send({image: video});
            }
        }, 60); // 15 FPS de IA (Suficiente para que sea fluido y no se cuelgue)
    }

    start().catch(console.error);
</script>
</body>
</html>
